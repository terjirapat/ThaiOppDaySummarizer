{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8db3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d91c6e4",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/687d132f-70f0-8003-8800-16c45376f179"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92157c8c",
   "metadata": {},
   "source": [
    "i extract subtitle from youtube video\n",
    "the video is 2hours long\n",
    "i want summarize with Key points of the video using llm model\n",
    "so i chunk subtitle every 10 minutes and input each chunk to model to summarize\n",
    "eg. 1 time summarize for 1 chunk\n",
    "and then I combine all the sumarize together\n",
    "I use this method because llm model seem to cunfuse when I input the large amount of data into it\n",
    "so I chunk it first and do all above\n",
    "is it a good method or any method suggest that better than this? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc77229",
   "metadata": {},
   "source": [
    "to do\n",
    "- try chunking in token \n",
    "    - 1,000–2,000 tokens per chunk is the safe sweet spot\n",
    "    - Add 10–20% overlap to catch mid-topic cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eab60894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://youtu.be/uDwwwQCeDUc?si=ODvCOaCrGTK9j_ud\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "title = soup.title.string.replace(\" - YouTube\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "713eedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# get video title name\n",
    "def clean_title(text):\n",
    "    return re.sub(r'[^0-9a-zA-Z\\u0E00-\\u0E7F\\.]', '', text)\n",
    "title = clean_title(text=title)\n",
    "\n",
    "# get video id\n",
    "match = re.search(r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\", url)\n",
    "if match:\n",
    "    video_id = match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0689e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# Fetch transcript (auto-captions or uploaded)\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['th', 'en'])\n",
    "\n",
    "# Optionally, save to file\n",
    "file_name = f'{title}_{video_id}'\n",
    "with open(f\"{file_name}_subtitle.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in transcript:\n",
    "        f.write(f\"{entry['start']:.2f}s: {entry['text']}\\n\")\n",
    "        # f.write(f\"{entry['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec099dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def load_subtitles(file_path):\n",
    "#     subtitles = []\n",
    "#     with open(file_path, encoding='utf-8') as f:\n",
    "#         for line in f:\n",
    "#             match = re.match(r'([0-9.]+)s:\\s(.+)', line.strip())\n",
    "#             if match:\n",
    "#                 start_time = float(match.group(1))\n",
    "#                 text = match.group(2)\n",
    "#                 subtitles.append({'start': start_time, 'text': text})\n",
    "#     return subtitles\n",
    "\n",
    "# def chunk_subtitles(subtitles, chunk_size=60, overlap=20):\n",
    "#     \"\"\"\n",
    "#     Chunk subtitles into segments of `chunk_size` seconds with `overlap` seconds.\n",
    "#     \"\"\"\n",
    "#     chunks = []\n",
    "#     max_time = subtitles[-1]['start']\n",
    "#     start_time = 0\n",
    "\n",
    "#     while start_time <= max_time:\n",
    "#         end_time = start_time + chunk_size\n",
    "#         chunk_text = []\n",
    "#         for entry in subtitles:\n",
    "#             if start_time <= entry['start'] < end_time:\n",
    "#                 chunk_text.append(entry['text'])\n",
    "#         if chunk_text:\n",
    "#             chunks.append({\n",
    "#                 'start': start_time,\n",
    "#                 'end': end_time,\n",
    "#                 'text': ' '.join(chunk_text)\n",
    "#             })\n",
    "#         start_time += chunk_size - overlap\n",
    "#     return chunks\n",
    "\n",
    "# subtitles = load_subtitles(f\"{file_name}_subtitle.txt\")\n",
    "# chunk_dict = chunk_subtitles(subtitles, chunk_size=600, overlap=60)\n",
    "# # chunk_dict = chunk_subtitles(subtitles, chunk_size=300, overlap=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bdf1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    \"\"\"Read text from a file and return as a string.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def remove_timestamps(text):\n",
    "    \"\"\"Remove timestamps like '0.12s:' at the start of each line.\"\"\"\n",
    "    cleaned_text = re.sub(r'^\\s*\\d+\\.\\d+s:\\s*', '', text, flags=re.MULTILINE)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_newlines(text):\n",
    "    \"\"\"Remove newline characters.\"\"\"\n",
    "    return text.replace('\\n', '')\n",
    "\n",
    "def chunk_thai_text(text, max_tokens, overlap):\n",
    "    \"\"\"\n",
    "    Chunk Thai text using PyThaiNLP word tokenizer with overlap.\n",
    "    \"\"\"\n",
    "    words = word_tokenize(text, keep_whitespace=False)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(words):\n",
    "        end = min(start + max_tokens, len(words))\n",
    "        chunk = ''.join(words[start:end])  # Join with no spaces for Thai\n",
    "        chunks.append(chunk)\n",
    "        start += max_tokens - overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage:\n",
    "file_path = f\"{file_name}_subtitle.txt\"\n",
    "text = read_text_file(file_path)\n",
    "text = remove_timestamps(text)\n",
    "text = remove_newlines(text)\n",
    "chunks = chunk_thai_text(text, max_tokens=1000, overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e285e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from package.model import ModelManager, OllamaRunner\n",
    "# from package.prompt import Prompt\n",
    "\n",
    "# system_prompt = \"\"\"\n",
    "# Read the following conversation and identify the main topics discussed. \n",
    "# Return only a concise list of topics, each as a short phrase or keyword, without extra explanation. \n",
    "# Avoid duplicates or overly specific details.\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# manager = ModelManager()\n",
    "# manager.register_runner(\"llama3\", OllamaRunner())\n",
    "\n",
    "# user_prompt = chunks[0]\n",
    "# prompt = Prompt(model_name=\"llama3\", user_prompt=user_prompt, system_prompt=system_prompt)\n",
    "\n",
    "# response = manager.run(prompt)\n",
    "\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c959756",
   "metadata": {},
   "source": [
    "## Use “Key points extraction” instead of general summary\n",
    "## Use hierarchical summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11d2b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.prompts import KEY_POINTS_PROMPT, SECTION_MERGE_PROMPT, FINAL_SUMMARY_PROMPT\n",
    "from package.model.ollama import query_ollama\n",
    "from package.model.gemini import query_gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "639f0879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting key points for each chunk...\n",
      "Chunk 1 done.\n",
      "Chunk 2 done.\n",
      "Chunk 3 done.\n",
      "Chunk 4 done.\n",
      "Chunk 5 done.\n",
      "Chunk 6 done.\n",
      "Chunk 7 done.\n",
      "\n",
      "Merging chunks into sections...\n",
      "Section 1 done.\n",
      "Section 2 done.\n",
      "Section 3 done.\n",
      "\n",
      "Merging all sections into final summary...\n",
      "Final summary done.\n"
     ]
    }
   ],
   "source": [
    "# === PIPELINE ===\n",
    "\n",
    "chunk_key_points = []\n",
    "print(\"Extracting key points for each chunk...\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    result = query_ollama(prompt=KEY_POINTS_PROMPT, user_prompt=chunk)\n",
    "    print(f\"Chunk {i+1} done.\")\n",
    "    chunk_key_points.append(result)\n",
    "\n",
    "# Group into sections, e.g., 3 chunks per section\n",
    "SECTION_SIZE = 3\n",
    "section_key_points = []\n",
    "\n",
    "print(\"\\nMerging chunks into sections...\")\n",
    "for i in range(0, len(chunk_key_points), SECTION_SIZE):\n",
    "    group = chunk_key_points[i:i+SECTION_SIZE]\n",
    "    group_text = \"\\n\\n\".join(group)\n",
    "    result = query_ollama(prompt=SECTION_MERGE_PROMPT, user_prompt=group_text)\n",
    "    print(f\"Section {i//SECTION_SIZE + 1} done.\")\n",
    "    section_key_points.append(result)\n",
    "\n",
    "# Final merge\n",
    "print(\"\\nMerging all sections into final summary...\")\n",
    "all_sections_text = \"\\n\\n\".join(section_key_points)\n",
    "final_summary = query_ollama(prompt=FINAL_SUMMARY_PROMPT, user_prompt=all_sections_text)\n",
    "print('Final summary done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd6d6c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a **single, well-organized summary** of the entire video:\n",
      "\n",
      "**Facts**\n",
      "• [Fact] The company's revenue in Q2 is 36% higher than last year, with a significant increase in Asia.\n",
      "• [Fact] Revenue in Q1 was lower than expected, but it has since recovered in Q2.\n",
      "• [Fact] The company's stock price has dropped by around 10%.\n",
      "• [Fact] The company's debt-to-equity ratio is around 10,200 million baht.\n",
      "• [Fact] The company's ROE is around 20%, with a net profit margin of around 17%.\n",
      "\n",
      "**Ideas**\n",
      "• [Idea] The speaker believes that the company's poor performance is due to its Q2 results, which were disappointing.\n",
      "• [Idea] Expanding the product line to include new categories can attract new customers; creating a strong brand identity can attract new customers.\n",
      "• [Idea] The company should focus on marketing to younger generations, such as those in the Philippines and Indonesia; localize its marketing efforts for each region; build relationships with influencers and content creators in each region.\n",
      "\n",
      "**Actions**\n",
      "• [Action] The speaker suggests that investors should consider the company's holding structure and focus on its drink segment.\n",
      "• [Action] Next step is to analyze the company's marketing strategy and adjust it according to market trends; focus on creating content for TikTok and other platforms; focus on selling products abroad, which has led to higher profits and a higher return on equity (ROE).\n",
      "• [Action] The course will provide 10 lessons on how to avoid losing money in the stock market.\n",
      "\n",
      "**Warnings**\n",
      "• [Warning] The company's financials are not as strong as they were in the past, and there may be risks associated with investing in it.\n",
      "\n",
      "Let me know if you'd like me to make any further changes!\n"
     ]
    }
   ],
   "source": [
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b10eb91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a **single, well-organized summary**:\n",
      "\n",
      "**Facts**\n",
      "\n",
      "* [Fact] People with a lot of money may struggle to find genuine friends.\n",
      "* [Fact] Having good friends is important, but it's not necessary to have many. A few genuine connections can be valuable.\n",
      "* [Fact] Having a certain amount of money (around 2 million baht) can provide privileges, such as being treated with respect and not needing to worry about small things.\n",
      "\n",
      "**Ideas**\n",
      "\n",
      "* [Idea] Having financial knowledge is crucial for achieving wealth and avoiding financial pitfalls.\n",
      "* [Idea] Having a clear understanding of financial concepts and being able to apply them effectively is key to achieving wealth.\n",
      "* [Idea] Investing in things one loves can lead to financial success.\n",
      "* [Idea] Having a few quality connections can be valuable.\n",
      "\n",
      "**Quotes**\n",
      "\n",
      "* [Quote] \"มันไม่ได้อยู่ที่ปริมาณ มันอยู่ที่คุณภาพ\" (It's not about quantity, it's about quality).\n",
      "* [Quote] \"People are equal as long as we don't take money from each other.\"\n",
      "* [Quote] \"Money is in the air\" - suggesting that having money can open up new possibilities.\n",
      "* [Quote] \"If you don't change, you'll be left behind.\"\n",
      "\n",
      "**Actions**\n",
      "\n",
      "* [Action] People with a lot of money should be careful and not get taken advantage of by those who only want to be around them for financial gain.\n",
      "* [Action] It's essential to be self-sufficient and not rely on others for success.\n",
      "* [Action] Prioritize building an emergency fund, having a solid financial plan, and being open and honest with family members about one's financial situation and goals.\n",
      "* [Action] Start investing in things you love, such as stocks or real estate, to achieve financial freedom.\n",
      "\n",
      "Note: I removed the question about why some people are hesitant to talk about their financial struggles with others, as it seems unrelated to the main topics of financial planning and family relationships.\n"
     ]
    }
   ],
   "source": [
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d85f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{file_name}_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
